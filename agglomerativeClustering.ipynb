{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eadbac-35c5-4613-bb5b-8f63b6d871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b448db9-75ff-4477-a559-a7011c9924e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "image_paths = glob('/home/utku/Masaüstü/BIL476/runs/detect/predict/crops/person/*.jpg') + glob('{HOME}/runs/detect/predict/crops/person/*.jpg') + glob('{HOME}/runs/detect/predict/crops/person/*.jpg')\n",
    "images=[]\n",
    "print(f\"Found {len(image_paths)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289414c9-6afe-468b-ba17-a8822a8ce4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images and handle errors\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Unable to load image: {image_path}\")\n",
    "        image = cv2.resize(image, target_size)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = preprocess_input(image)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Preprocessing images...\")\n",
    "preprocessed_images = [preprocess_image(img_path) for img_path in image_paths]\n",
    "preprocessed_images = [img for img in preprocessed_images if img is not None]  # Filter out failed images\n",
    "\n",
    "# Ensure there are images to process\n",
    "if len(preprocessed_images) == 0:\n",
    "    raise ValueError(\"No valid images found. Please check the image paths and formats.\")\n",
    "\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "print(f\"Shape of preprocessed images: {preprocessed_images.shape}\")\n",
    "\n",
    "# Load VGG16 model + higher level layers\n",
    "print(\"Loading VGG16 model...\")\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "# Extract features in smaller batches to handle memory issues\n",
    "batch_size = 16\n",
    "features = []\n",
    "\n",
    "print(\"Extracting features in batches...\")\n",
    "for i in range(0, len(preprocessed_images), batch_size):\n",
    "    batch = preprocessed_images[i:i + batch_size]\n",
    "    try:\n",
    "        batch_features = model.predict(batch)\n",
    "        features.append(batch_features)\n",
    "        print(f\"Processed batch {i // batch_size + 1}/{len(preprocessed_images) // batch_size + 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "print(f\"Shape of extracted features: {features.shape}\")\n",
    "\n",
    "# Reduce dimensionality for faster clustering\n",
    "print(\"Performing PCA to reduce dimensionality...\")\n",
    "try:\n",
    "    pca = PCA(n_components=50)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    print(f\"Shape of reduced features: {reduced_features.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during PCA transformation: {e}\")\n",
    "    reduced_features = features  # Fall back to original features if PCA fails\n",
    "\n",
    "# Initial KMeans clustering\n",
    "print(\"Performing initial KMeans clustering...\")\n",
    "try:\n",
    "    kmeans = KMeans(n_clusters=10)  # Start with a higher number of clusters\n",
    "    kmeans.fit(reduced_features)\n",
    "    initial_labels = kmeans.labels_\n",
    "    print(\"KMeans clustering completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during KMeans clustering: {e}\")\n",
    "    initial_labels = np.zeros(len(reduced_features))  # Fall back to a single cluster\n",
    "\n",
    "# Define desired cluster size range\n",
    "min_cluster_size = 3\n",
    "max_cluster_size = 10\n",
    "\n",
    "# Function to merge small clusters and split large clusters\n",
    "def adjust_cluster_sizes(labels, features, min_size, max_size):\n",
    "    print(\"Adjusting cluster sizes...\")\n",
    "    label_counts = collections.Counter(labels)\n",
    "    unique_labels = list(label_counts.keys())\n",
    "    print(f\"Initial label counts: {label_counts}\")\n",
    "    \n",
    "    new_labels = labels.copy()\n",
    "    next_label = max(unique_labels) + 1\n",
    "    \n",
    "    # Merge small clusters\n",
    "    for label in unique_labels:\n",
    "        if label_counts[label] < min_size:\n",
    "            print(f\"Merging small cluster {label} with {label_counts[label]} images.\")\n",
    "            # Find the nearest cluster to merge\n",
    "            cluster_indices = np.where(labels == label)[0]\n",
    "            cluster_features = features[cluster_indices]\n",
    "            distances = np.linalg.norm(features[:, None] - cluster_features[None, :], axis=2).mean(axis=1)\n",
    "            nearest_label = np.argmin([distances[labels == lbl].mean() for lbl in unique_labels if lbl != label])\n",
    "            new_labels[cluster_indices] = nearest_label\n",
    "    \n",
    "    # Split large clusters\n",
    "    for label in unique_labels:\n",
    "        if label_counts[label] > max_size:\n",
    "            print(f\"Splitting large cluster {label} with {label_counts[label]} images.\")\n",
    "            cluster_indices = np.where(labels == label)[0]\n",
    "            cluster_features = features[cluster_indices]\n",
    "            sub_kmeans = KMeans(n_clusters=(label_counts[label] // max_size) + 1)\n",
    "            sub_labels = sub_kmeans.fit_predict(cluster_features)\n",
    "            for sub_label in np.unique(sub_labels):\n",
    "                new_labels[cluster_indices[sub_labels == sub_label]] = next_label\n",
    "                next_label += 1\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "# Adjust cluster sizes\n",
    "adjusted_labels = adjust_cluster_sizes(initial_labels, reduced_features, min_cluster_size, max_cluster_size)\n",
    "print(\"Cluster size adjustment completed.\")\n",
    "\n",
    "# Function to plot clusters\n",
    "def plot_clusters(images, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    fig, ax = plt.subplots(len(unique_labels), 1, figsize=(15, 5*len(unique_labels)))\n",
    "    \n",
    "    if len(unique_labels) == 1:\n",
    "        ax = [ax]\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        cluster_indices = np.where(labels == label)[0]\n",
    "        cluster_images = [images[idx] for idx in cluster_indices]\n",
    "        \n",
    "        for idx, img in enumerate(cluster_images):\n",
    "            ax[label].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            ax[label].axis('off')\n",
    "        ax[label].set_title(f'Cluster {label} - {len(cluster_indices)} images')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"Plotting adjusted clusters...\")\n",
    "# Plot adjusted clusters\n",
    "plot_clusters(images, adjusted_labels)\n",
    "print(\"Script completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
